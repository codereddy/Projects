{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 8836: expected 4 fields, saw 5\n",
      "\n",
      "Skipping line 535882: expected 4 fields, saw 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('TwitterTrainingData.csv','rb',delimiter=',',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_train=df.ix[:90000,3].values\n",
    "labels_train=df.ix[:90000,1].values\n",
    "tweets_test=df.ix[90000:100000,3].values\n",
    "labels_test=df.ix[90000:100000,1].values\n",
    "\n",
    "# to remove the non ascii characters fromt the tweets\n",
    "for k in xrange(len(tweets_train)):\n",
    "    tweets_train[k]=''.join([i if ord(i) < 128 else '' for i in str(tweets_train[k])])\n",
    "\n",
    "    # to remove the non ascii characters fromt the tweets\n",
    "for k in xrange(len(tweets_test)):\n",
    "    tweets_test[k]=''.join([i if ord(i) < 128 else '' for i in str(tweets_test[k])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75102489751024892"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the count vectorizer, tfidf transformer for preprocessing of the text, and naive bayes classifier for training\n",
    "text_clf_NB = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer(use_idf=False)),('clf', MultinomialNB()),])\n",
    "text_clf_NB.fit(tweets_train,labels_train)\n",
    "#save the model as a pickle file\n",
    "pickle.dump(text_clf_NB,open('NbClassifier.p','wb'))\n",
    "\n",
    "predictions_NB=text_clf_NB.predict(tweets_test)\n",
    "\n",
    "np.mean(predictions_NB==labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71412858714128591"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the count vectorizer, tfidf transformer for preprocessing of the text, and Svm classifier for training\n",
    "text_clf_SVM = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer(use_idf=False)),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42)),])\n",
    "text_clf_SVM.fit(tweets_train, labels_train)\n",
    "#save the model as pickle file\n",
    "pickle.dump(text_clf_SVM,open('SvmClassifier.p','wb'))\n",
    "\n",
    "predictions_SVM = text_clf_SVM.predict(tweets_test)\n",
    "\n",
    "np.mean(predictions_SVM == labels_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.51      0.62      4006\n",
      "          1       0.74      0.91      0.81      5995\n",
      "\n",
      "avg / total       0.76      0.75      0.74     10001\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.49      0.58      4006\n",
      "          1       0.72      0.87      0.78      5995\n",
      "\n",
      "avg / total       0.71      0.71      0.70     10001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reporting the stats about the performance of each of the classifier\n",
    "print(metrics.classification_report(labels_test, predictions_NB))\n",
    "\n",
    "print(metrics.classification_report(labels_test, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
